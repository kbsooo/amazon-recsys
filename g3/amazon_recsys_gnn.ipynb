{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Amazon RecSys GNN - LightGCN Implementation\n",
                "\n",
                "이 노트북에서는 LightGCN 모델을 구현하고 학습시킵니다.\n",
                "또한 새로운 평가 규칙(50% 제한, 10개 이하 유저 2개 추천)을 적용하여 결과를 생성합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm import tqdm\n",
                "import pickle\n",
                "import scipy.sparse as sp\n",
                "import os\n",
                "\n",
                "# 시드 고정\n",
                "def seed_everything(seed=42):\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "seed_everything(42)\n",
                "\n",
                "# 디바이스 설정\n",
                "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 데이터 로드\n",
                "print('Loading data...')\n",
                "train_df = pd.read_csv('../g3/train_data.csv')\n",
                "test_df = pd.read_csv('../g3/test_data.csv')\n",
                "\n",
                "with open('../g3/user_mapper.pkl', 'rb') as f:\n",
                "    user_mapper = pickle.load(f)\n",
                "with open('../g3/item_mapper.pkl', 'rb') as f:\n",
                "    item_mapper = pickle.load(f)\n",
                "\n",
                "n_users = len(user_mapper)\n",
                "n_items = len(item_mapper)\n",
                "\n",
                "print(f'Users: {n_users}, Items: {n_items}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Adjacency Matrix 생성 (Sparse Tensor)\n",
                "def create_adj_matrix(df, n_users, n_items):\n",
                "    u = df['user_idx'].values\n",
                "    i = df['item_idx'].values\n",
                "    \n",
                "    user_np = np.array(u)\n",
                "    item_np = np.array(i)\n",
                "    \n",
                "    ratings = np.ones_like(user_np, dtype=np.float32)\n",
                "    \n",
                "    n_nodes = n_users + n_items\n",
                "    \n",
                "    # Direct COO Construction\n",
                "    tmp_adj = sp.coo_matrix((ratings, (user_np, item_np + n_users)), shape=(n_nodes, n_nodes))\n",
                "    adj_mat = tmp_adj + tmp_adj.T\n",
                "    \n",
                "    # Normalize\n",
                "    rowsum = np.array(adj_mat.sum(axis=1))\n",
                "    d_inv = np.power(rowsum, -0.5).flatten()\n",
                "    d_inv[np.isinf(d_inv)] = 0.\n",
                "    d_mat = sp.diags(d_inv)\n",
                "    \n",
                "    norm_adj = d_mat.dot(adj_mat).dot(d_mat)\n",
                "    norm_adj = norm_adj.tocoo()\n",
                "    \n",
                "    indices = torch.from_numpy(np.vstack((norm_adj.row, norm_adj.col)).astype(np.int64))\n",
                "    values = torch.from_numpy(norm_adj.data.astype(np.float32))\n",
                "    shape = torch.Size(norm_adj.shape)\n",
                "    \n",
                "    return torch.sparse_coo_tensor(indices, values, shape)\n",
                "\n",
                "print('Creating Adjacency Matrix...')\n",
                "adj_matrix = create_adj_matrix(train_df, n_users, n_items)\n",
                "adj_matrix = adj_matrix.to(device)\n",
                "print('Adjacency Matrix created.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LightGCN 모델 정의\n",
                "class LightGCN(nn.Module):\n",
                "    def __init__(self, n_users, n_items, emb_dim=64, n_layers=3):\n",
                "        super(LightGCN, self).__init__()\n",
                "        self.n_users = n_users\n",
                "        self.n_items = n_items\n",
                "        self.emb_dim = emb_dim\n",
                "        self.n_layers = n_layers\n",
                "        \n",
                "        self.user_embedding = nn.Embedding(n_users, emb_dim)\n",
                "        self.item_embedding = nn.Embedding(n_items, emb_dim)\n",
                "        \n",
                "        nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
                "        nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
                "        \n",
                "    def forward(self, adj_matrix):\n",
                "        all_emb = torch.cat([self.user_embedding.weight, self.item_embedding.weight])\n",
                "        embs = [all_emb]\n",
                "        \n",
                "        for layer in range(self.n_layers):\n",
                "            all_emb = torch.sparse.mm(adj_matrix, all_emb)\n",
                "            embs.append(all_emb)\n",
                "            \n",
                "        embs = torch.stack(embs, dim=1)\n",
                "        final_emb = torch.mean(embs, dim=1)\n",
                "        \n",
                "        users_emb, items_emb = torch.split(final_emb, [self.n_users, self.n_items])\n",
                "        return users_emb, items_emb"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# BPR Loss\n",
                "class BPRLoss(nn.Module):\n",
                "    def __init__(self, decay=1e-4):\n",
                "        super(BPRLoss, self).__init__()\n",
                "        self.decay = decay\n",
                "        \n",
                "    def forward(self, users_emb, items_emb, users, pos_items, neg_items, current_user_emb, current_pos_item_emb, current_neg_item_emb):\n",
                "        u_emb = users_emb[users]\n",
                "        pos_emb = items_emb[pos_items]\n",
                "        neg_emb = items_emb[neg_items]\n",
                "        \n",
                "        pos_scores = torch.sum(u_emb * pos_emb, dim=1)\n",
                "        neg_scores = torch.sum(u_emb * neg_emb, dim=1)\n",
                "        \n",
                "        loss = -torch.mean(torch.nn.functional.logsigmoid(pos_scores - neg_scores))\n",
                "        \n",
                "        reg_loss = (1/2) * (current_user_emb.norm(2).pow(2) + \n",
                "                            current_pos_item_emb.norm(2).pow(2) + \n",
                "                            current_neg_item_emb.norm(2).pow(2)) / float(len(users))\n",
                "        \n",
                "        return loss + self.decay * reg_loss\n",
                "\n",
                "# Dataset\n",
                "class TrainDataset(Dataset):\n",
                "    def __init__(self, df, n_items):\n",
                "        self.users = df['user_idx'].values\n",
                "        self.items = df['item_idx'].values\n",
                "        self.n_items = n_items\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.users)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        user = self.users[idx]\n",
                "        pos_item = self.items[idx]\n",
                "        \n",
                "        while True:\n",
                "            neg_item = np.random.randint(0, self.n_items)\n",
                "            if neg_item != pos_item:\n",
                "                break\n",
                "                \n",
                "        return user, pos_item, neg_item"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hyperparameters\n",
                "EMB_DIM = 64\n",
                "N_LAYERS = 2\n",
                "BATCH_SIZE = 2048\n",
                "LR = 0.001\n",
                "EPOCHS = 5\n",
                "DECAY = 1e-4\n",
                "\n",
                "print('Initializing Model...')\n",
                "model = LightGCN(n_users, n_items, EMB_DIM, N_LAYERS).to(device)\n",
                "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
                "criterion = BPRLoss(decay=DECAY)\n",
                "\n",
                "train_dataset = TrainDataset(train_df, n_items)\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "\n",
                "print('Starting Training...')\n",
                "loss_history = []\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    \n",
                "    for users, pos_items, neg_items in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}'):\n",
                "        users = users.to(device)\n",
                "        pos_items = pos_items.to(device)\n",
                "        neg_items = neg_items.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        users_emb, items_emb = model(adj_matrix)\n",
                "        \n",
                "        current_user_emb = model.user_embedding(users)\n",
                "        current_pos_item_emb = model.item_embedding(pos_items)\n",
                "        current_neg_item_emb = model.item_embedding(neg_items)\n",
                "        \n",
                "        loss = criterion(users_emb, items_emb, users, pos_items, neg_items, \n",
                "                         current_user_emb, current_pos_item_emb, current_neg_item_emb)\n",
                "        \n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        \n",
                "    avg_loss = total_loss / len(train_loader)\n",
                "    loss_history.append(avg_loss)\n",
                "    print(f'Epoch {epoch+1} Loss: {avg_loss:.4f}')\n",
                "\n",
                "# Plot Loss\n",
                "plt.plot(loss_history)\n",
                "plt.title('Training Loss')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 모델 저장\n",
                "torch.save(model.state_dict(), '../g3/lightgcn_model.pt')\n",
                "print('Model saved.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluation (Custom Logic)\n",
                "print('Evaluating...')\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    users_emb, items_emb = model(adj_matrix)\n",
                "\n",
                "user_history = train_df.groupby('user_idx')['item_idx'].apply(list).to_dict()\n",
                "\n",
                "def get_recommendations(user_idx, k=20):\n",
                "    u_emb = users_emb[user_idx]\n",
                "    scores = torch.matmul(items_emb, u_emb)\n",
                "    \n",
                "    seen_items = user_history.get(user_idx, [])\n",
                "    scores[seen_items] = -float('inf')\n",
                "    \n",
                "    _, top_k_items = torch.topk(scores, k)\n",
                "    return top_k_items.cpu().numpy()\n",
                "\n",
                "results = []\n",
                "test_users = test_df['user_idx'].unique()\n",
                "\n",
                "# Sample 100 users for quick check\n",
                "sample_users = np.random.choice(test_users, 100, replace=False)\n",
                "\n",
                "for u_idx in tqdm(sample_users, desc='Generating Recommendations'):\n",
                "    history_count = len(user_history.get(u_idx, []))\n",
                "    \n",
                "    if history_count <= 10:\n",
                "        num_to_recommend = 2\n",
                "    else:\n",
                "        num_to_recommend = int(history_count * 0.5)\n",
                "        if num_to_recommend < 1: num_to_recommend = 1\n",
                "    \n",
                "    recs = get_recommendations(u_idx, k=num_to_recommend)\n",
                "    \n",
                "    gt_items = test_df[test_df['user_idx'] == u_idx]['item_idx'].values\n",
                "    \n",
                "    hits = np.intersect1d(recs, gt_items)\n",
                "    recall = len(hits) / len(gt_items) if len(gt_items) > 0 else 0\n",
                "    \n",
                "    results.append({\n",
                "        'user_idx': u_idx,\n",
                "        'history_count': history_count,\n",
                "        'num_recommends': num_to_recommend,\n",
                "        'hits': len(hits),\n",
                "        'recall': recall\n",
                "    })\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "print('Average Recall (Sampled):', results_df['recall'].mean())\n",
                "print(results_df.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}